{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31fa78c7",
   "metadata": {},
   "source": [
    "### **1. Import libraries and dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cedb82",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np ## pip install numpy==2.1 #need this to run ydata-profiling\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency # filter method\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from ydata_profiling import ProfileReport \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80535567",
   "metadata": {},
   "source": [
    "Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current notebook's directory (notebooks folder)\n",
    "base_path = Path.cwd()\n",
    "\n",
    "# Get the project root (parent of notebooks folder)\n",
    "project_root = base_path.parent\n",
    "\n",
    "# Build the path to the dataset\n",
    "data_path = project_root / \"data\" / \"processed\" / \"HR_1_1.csv\"\n",
    "\n",
    "# Load the file\n",
    "HR_1_1 = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Loaded HR_1_1 from: {data_path}\")\n",
    "print(f\"Dataset shape: {HR_1_1.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0face96",
   "metadata": {},
   "source": [
    "## **2. Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd30c4a",
   "metadata": {},
   "source": [
    "The purpose of this section is to analyze potential correlations among the various variables in the dataset as a form of filter **Feature Selection**.\n",
    "\n",
    "**Numerical features** were scaled using `MinMaxScaler()`. **Categorical features** were **encoded** and converted into numerical representations so that machine learning algorithms can process and interpret them effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d5eda",
   "metadata": {},
   "source": [
    "### **2.1. Spearman correlation analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f270c7",
   "metadata": {},
   "source": [
    "Spearman is useful to understand if there are redundant features with high correlation to disconsider. It is suitable for continuous and ordinal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_HR_1_1 = HR_1_1.corr(method='spearman', numeric_only=True)\n",
    "correlation_HR_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9199c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_columns = sorted(correlation_HR_1_1.columns)\n",
    "correlation_HR_1_1_sorted = correlation_HR_1_1.loc[sorted_columns, sorted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(correlation_HR_1_1_sorted, cmap=\"PRGn\", square=True, linewidths=0.5, annot=False, cbar_kws={\n",
    "        'shrink': 0.6,      # Makes colorbar smaller (60% of default)\n",
    "        'aspect': 30,        # Makes colorbar narrower\n",
    "        'pad': 0.02          # Adds space between plot and colorbar\n",
    "    })\n",
    "plt.title(\"Numerical Correlations (Spearman)\")\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d1ea7",
   "metadata": {},
   "source": [
    "#### **Insights**\n",
    "**Highlights of features and target category:**\n",
    "\n",
    "The image above allows to conclude that aren't strong correlations between the features and the target variable (Attrition). However, some points to hightlight \n",
    "\n",
    "- **Attrition and Age:** the spearman correlation coefficient is -0.171214, which is a negative relationship. This can be interpreted as the age increases the attrition score decreases, so <u>older employees are less likely to leave the company</u>. However, the score is low so the variable by itself doesn't explain the attrition. \n",
    "\n",
    "- **Attrition and Job Level:** the spearman correlation coefficient is -0.190370, also a negative relationship. The job level variable represents the hierarchy at the company and this suggests that <u> as the level is higher, the attrition score decreases</u>.\n",
    "\n",
    "- **Attrition and Monthly Income:** the spearman correlation coefficient is -0.199086, also a negative relationship. As the monthly income increases the attrition score tends to be lower, indicating that <u>higher incomes are associated with a lower rate of employee turnover</u>.\n",
    "\n",
    "- **Attrition and Total Working Years:** the spearman correlation coefficient is -0.199320, which indicates that <u>more years working represents a decrease in the attrition score</u>. It corroborates the age seen previously, although it is interesting that the age itself doesn't have a strong correlation with the total working years.\n",
    "\n",
    "- **Attrition and Years at the Company:** the spearman correlation coefficient is -0.191121, which indicates a <u>lower score of attrition when the employee has more years of work in the company</u>.\n",
    "\n",
    "- **Attrition and Years in the Current Role:** the spearman correlation coefficient is -0.180566, indicates that <u>more years in the current rule are slightly related with lower attrition score</u>.\n",
    "\n",
    "- **Attrition and Years with the Current Manager:** the spearman correlation coefficient is -0.175355, indicates that <u>more years with the current manager represents a lower attrition score</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b3dbe",
   "metadata": {},
   "source": [
    "**Highlights of other feature relations:**\n",
    "\n",
    "The strongest correlation coefficients -  the darkest spots were observed among the dummy variables for features like Department, Gender, and Marital Status due to the structural artifacts of the data encoding process, not signals of real-world predictive power. \n",
    "\n",
    "These strong relationships, particularly the high negative ones, result from multicollinearity. When a categorical feature with $N$ options is converted into $N$ binary dummy columns (e.g., Gender_Male and Gender_Female), the columns are perfectly or near-perfectly dependent: if one is 1' (True), the other(s) must be '0' (False). \n",
    "\n",
    "For instance, the perfect negative correlation of $-1.0$ between Gender_Male and Gender_Female simply confirms that a person cannot be both simultaneously. \n",
    "\n",
    "While mathematically sound, these high correlations are uninformative for predicting Attrition and would be ignored when assessing external factors influencing employee turnover.\n",
    "\n",
    "The focus must remain on the weaker, yet meaningful, correlations found between the demographic/satisfaction variables and the target variable, Attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb344ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation1 = HR_1_1.corr(method='spearman', numeric_only=True)\n",
    "\n",
    "sorted_columns = sorted(correlation1.columns)\n",
    "correlation1_sorted = correlation1.loc[sorted_columns, sorted_columns]\n",
    "\n",
    "numeric_cols = HR_1_1.select_dtypes(include=['number']).columns\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#correlation1[numeric_cols] = scaler.fit_transform(correlation1[numeric_cols])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation1_sorted, cmap=\"PRGn\", square=True, linewidths=0.5, vmin=-0.6, vmax=0.6, annot=False)\n",
    "plt.title(\"Numerical Correlations (Spearman)\")\n",
    "plt.xticks(rotation=90, fontsize=9)\n",
    "plt.yticks(rotation=0, fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d0c2b",
   "metadata": {},
   "source": [
    "### **2.2. Remove redundant variables (>0.65 correlation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb4251b",
   "metadata": {},
   "source": [
    "Use the variables studied on the Spearman correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation1_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87d90f",
   "metadata": {},
   "source": [
    "- Age (-0.17) is highly overall correlated with **TotalWorkingYears** (-0.20)\n",
    "- Department (0.08) is highly overall correlated with EducationField (0.07) and JobRole (0.16)\n",
    "- EducationField (0.07) is highly overall correlated with Department (0.08)\n",
    "- JobLevel (-0.19) is highly overall correlated with JobRole (0.16),  MonthlyIncome (0.015), and **TotalWorkingYears (-0.20)**\n",
    "- JobRole (0.16) is highly overall correlated with Department (0.08) and JobLevel (-0.19)\n",
    "- **MaritalStatus (0.18)** is highly overall correlated with StockOptionLevel (-0.17)\n",
    "- MonthlyIncome (0.015) is highly overall correlated with JobLevel (-0.19) and **TotalWorkingYears** (-0.20)\n",
    "- **PercentSalaryHike (-0.02)** is highly overall correlated with PerformanceRating (---)\n",
    "- PerformanceRating (---) is highly overall correlated with PercentSalaryHike (-0.02)\n",
    "- StockOptionLevel (-0.17) is highly overall correlated with **MaritalStatus** (0.18)\n",
    "- **TotalWorkingYears (-0.20)** is highly overall correlated with Age (-0.17), JobLevel (-0.19), YearsAtCompany (-0.19) and MonthlyIncome (0.015)\n",
    "- YearsAtCompany (-0.19) is highly overall correlated with **TotalWorkingYears (-0.20)**, YearsInCurrentRole (-0.18), YearsSinceLastPromotion (-0.05), YearsWithCurrManager (-0.18) \n",
    "- YearsInCurrentRole (-0.18) is highly overall correlated with **YearsAtCompany (-0.19)**, YearsSinceLastPromotion (-0.05), YearsWithCurrManager (-0.18)\n",
    "- YearsSinceLastPromotion (-0.05) is highly overall correlated with YearsAtCompany (-0.19) and YearsInCurrentRole (-0.18)\n",
    "- YearsWithCurrManager (-0.18) is highly overall correlated with YearsAtCompany (-0.19) and YearsInCurrentRole (-0.18)\n",
    "\n",
    "**If two variables are correlated, we drop one of them, keeping the variable with largest correlation with the target**\n",
    "\n",
    "Remove:\n",
    "- Age\n",
    "- Department\n",
    "- EducationField\n",
    "- JobLevel\n",
    "- JobRole\n",
    "- StockOptionLevel\n",
    "- MonthlyIncome\n",
    "- PerformanceRating\n",
    "- YearsInCurrentRole\n",
    "\n",
    "Keep:\n",
    "- TotalWorkingYears\n",
    "- MaritalStatus\n",
    "- PercentSalaryHike\n",
    "- YearsAtCompany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If two variables are correlated, we drop one of them, keeping the variable with largest correlation with the target\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = HR_1_1.corr().abs()\n",
    "\n",
    "# Target variable correlation\n",
    "target = 'Attrition'\n",
    "target_corr = corr_matrix[target].drop(target)  # drop self-correlation\n",
    "\n",
    "# Correlation threshold\n",
    "threshold = 0.65\n",
    "\n",
    "# Initialize set for dropped columns\n",
    "drop_cols = set()\n",
    "\n",
    "# Iterate over the upper triangle of the correlation matrix\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    col1 = corr_matrix.columns[i]\n",
    "    if col1 == target or col1 in drop_cols:\n",
    "        continue\n",
    "\n",
    "    for j in range(i + 1, len(corr_matrix.columns)):\n",
    "        col2 = corr_matrix.columns[j]\n",
    "        if col2 == target or col2 in drop_cols:\n",
    "            continue\n",
    "\n",
    "        # Check correlation between two features\n",
    "        if corr_matrix.iloc[i, j] > threshold:\n",
    "            # Compare correlation with target\n",
    "            corr1 = target_corr.get(col1, 0)\n",
    "            corr2 = target_corr.get(col2, 0)\n",
    "\n",
    "            # Drop the one with smaller correlation to target\n",
    "            if corr1 >= corr2:\n",
    "                drop_cols.add(col2)\n",
    "            else:\n",
    "                drop_cols.add(col1)\n",
    "\n",
    "print(\"Columns to drop due to high correlation:\", drop_cols)\n",
    "print(\"Number of columns to drop:\", len(drop_cols))\n",
    "\n",
    "# Create final dataset\n",
    "HR_final = HR_1_1.drop(columns=list(drop_cols))\n",
    "print(\"Final dataset shape:\", HR_final.shape)\n",
    "HR_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e7cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kept columns:\", [c for c in HR_final.columns if c not in drop_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658361a",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "From the redundant variables (>0.65 Spearman Correlation) we decided to:\n",
    "\n",
    "Remove:\n",
    "- Age\n",
    "- Department\n",
    "- EducationField\n",
    "- JobLevel\n",
    "- JobRole\n",
    "- StockOptionLevel\n",
    "- MonthlyIncome\n",
    "- PerformanceRating\n",
    "- YearsInCurrentRole\n",
    "\n",
    "Keep:\n",
    "- TotalWorkingYears\n",
    "- MaritalStatus\n",
    "- PercentSalaryHike\n",
    "- YearsAtCompany"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2079070e",
   "metadata": {},
   "source": [
    "Non-redundant variables to keep in the dataset:\n",
    "- EmployeeNumber\n",
    "- Attrition\n",
    "- DailyRate\n",
    "- DistanceFromHome\n",
    "- Education\n",
    "- EnvironmentSatisfaction\n",
    "- HourlyRate\n",
    "- JobInvolvement\n",
    "- JobSatisfaction\n",
    "- NumCompaniesWorked\n",
    "- PercentSalaryHike\n",
    "- PerformanceRating\n",
    "- RelationshipSatisfaction\n",
    "- TrainingTimesLastYear\n",
    "- WorkLifeBalance\n",
    "- TotalWorkingYearsLog\n",
    "- YearsAtCompanyLog\n",
    "- YearsSinceLastPromotionLog\n",
    "- Department_Research & Development\n",
    "- EducationField_Human Resources\n",
    "- EducationField_Life Sciences\n",
    "- EducationField_Marketing\n",
    "- EducationField_Medical\n",
    "- EducationField_Technical Degree\n",
    "- JobRole_Healthcare Representative\n",
    "- JobRole_Human Resources\n",
    "- JobRole_Laboratory Technician\n",
    "- JobRole_Manager\n",
    "- JobRole_Manufacturing Director\n",
    "- JobRole_Research Director\n",
    "- JobRole_Research Scientist\n",
    "- JobRole_Sales Representative\n",
    "- BusinessTravel_Travel_Frequently\n",
    "- Gender_Male\n",
    "- MaritalStatus_Married\n",
    "- MaritalStatus_Single\n",
    "- OverTime_Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61efaa",
   "metadata": {},
   "source": [
    "### **2.3. Applying StratifiedKFold with chi-squared contingency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af7632",
   "metadata": {},
   "source": [
    "We can use StratifiedKFold to better grasp the variables required to predict the Attrition target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d18996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def select_best_cat_features(X, y, columns, n_splits=5, alpha=0.05):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    categorical_cols = columns\n",
    "\n",
    "    significance_counts = {col: 0 for col in categorical_cols}\n",
    "\n",
    "    for count, (train_index, val_index) in enumerate(skf.split(X, y), start=1):\n",
    "        print(f'\\n{\"_\"*40}\\nSPLIT {count}\\n')\n",
    "\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_cat = X_train[categorical_cols]\n",
    "\n",
    "        for col in X_cat.columns:\n",
    "            contingency = pd.crosstab(X_cat[col], y_train)\n",
    "\n",
    "            # --- NEW: skip empty tables ---\n",
    "            if contingency.size == 0:\n",
    "                print(f\"{col}: skipped (empty contingency table)\")\n",
    "                continue\n",
    "\n",
    "            # --- NEW: require at least TWO categories and TWO classes ---\n",
    "            if contingency.shape[0] < 2 or contingency.shape[1] < 2:\n",
    "                print(f\"{col}: skipped (not enough categories/classes)\")\n",
    "                continue\n",
    "\n",
    "            _, p, _, _ = chi2_contingency(contingency)\n",
    "            if p < alpha:\n",
    "                print(f\"{col}: SIGNIFICANT (p={p:.4f})\")\n",
    "                significance_counts[col] += 1\n",
    "            else:\n",
    "                print(f\"{col}: NOT significant (p={p:.4f})\")\n",
    "\n",
    "    print(\"\\nSummary of significance across splits:\")\n",
    "    summary = pd.DataFrame.from_dict(significance_counts, orient='index', columns=['Significant_Splits'])\n",
    "    summary['% Splits Significant'] = (summary['Significant_Splits'] / n_splits) * 100\n",
    "    return summary.sort_values(by='Significant_Splits', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which variables significantly associate with the Attrition target variable\n",
    "y = HR_final['Attrition'].copy()\n",
    "X = HR_final.drop(columns=['Attrition']).copy()\n",
    "\n",
    "# Select categorical and binary-like columns\n",
    "columns = X.columns.tolist()\n",
    "\n",
    "# Run Chi-Squared feature selection\n",
    "result_df = select_best_cat_features(X, y, columns=columns)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictors = result_df[result_df['% Splits Significant'] >= 80].index.tolist()\n",
    "print(\"Best predictors (significant in at least 80% of splits):\", best_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9fbb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_best_predictors = [col for col in best_predictors if col in HR_final.columns]\n",
    "\n",
    "missing = [col for col in best_predictors if col not in HR_final.columns]\n",
    "\n",
    "print(\"Missing columns:\", missing)\n",
    "print(\"Using predictors:\", valid_best_predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb699a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create best dataframe\n",
    "HR_best = HR_final[best_predictors + ['Attrition']].copy()\n",
    "#sorted_best_columns = sorted(HR_best.columns)\n",
    "#HR_best_sorted = HR_best.loc[sorted_best_columns, sorted_best_columns]\n",
    "HR_best = HR_best.reindex(sorted(HR_best.columns), axis=1)\n",
    "HR_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac1dd7",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "The variables: \n",
    "- BusinessTravel\n",
    "- Department\n",
    "- EnvironmentSatisfaction\n",
    "- JobInvolvement\n",
    "- JobRole\n",
    "- JobSatisfaction \n",
    "- MaritalStatus\n",
    "- NumCompaniesWorked\n",
    "- OverTime  \n",
    "- TotalWorkingYears\n",
    "- WorkLifeBalance\n",
    "- YearsAtCompany\n",
    "\n",
    "all seem relevant to predict if a person will leave the company or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman correlation of the best dataset for predicting Attrition\n",
    "correlation_HR_best = HR_best.corr(method='spearman', numeric_only=True)\n",
    "correlation_HR_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c145286",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_columns = sorted(correlation_HR_best.columns)\n",
    "correlation_HR_best_sorted = correlation_HR_best.loc[sorted_columns, sorted_columns]\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(correlation_HR_best_sorted, cmap=\"PRGn\", square=True, vmin=-0.6, vmax=0.6, linewidths=0.5, annot=False, cbar_kws={\n",
    "        'shrink': 0.6,      # Makes colorbar smaller (60% of default)\n",
    "        'aspect': 30,        # Makes colorbar narrower\n",
    "        'pad': 0.02          # Adds space between plot and colorbar\n",
    "    })\n",
    "plt.title(\"Numerical Correlations (Spearman)\")\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309df33b",
   "metadata": {},
   "source": [
    "Now there are no more correlations > 0.65 (the cut-off utilised before).\n",
    "\n",
    "Single and Married should both stay because, although they are mildly correlated, they are both involved in predicting the target and there is a Divorced class that can be inferred from the values of both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9dd1a",
   "metadata": {},
   "source": [
    "## **3. Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c9cae",
   "metadata": {},
   "source": [
    "### **3.1. Create new variables based on domain knowledge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea3c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse if big differences between monthly rates and montly income may influence the target variable.\n",
    "HR_best['rate_income'] = HR_1_1['MonthlyRate'] - HR_1_1['MonthlyIncome']\n",
    "#HR_best['Income_per_YearAtCompany'] = HR_best['MonthlyIncomeLog'] / (HR_best['YearsAtCompanyLog'] + 1) # unfortunately MonthlyIncomeLog was dropped\n",
    "HR_best['WorkLifeBalance_OverTime'] = HR_best['WorkLifeBalance'] - HR_best['OverTime_Yes'] # -> -0.23 correlation\n",
    "HR_best['Job_happiness_score'] = HR_best['JobInvolvement'] + HR_best['JobSatisfaction'] + HR_best['YearsAtCompanyLog'] + HR_best['EnvironmentSatisfaction'] + HR_best['WorkLifeBalance'] - HR_best['OverTime_Yes'] #-> -0.33 correlation\n",
    "# HR_best['Job_happiness_score_test'] = (HR_best['JobInvolvement'] * HR_best['JobSatisfaction'] * HR_best['YearsAtCompanyLog'] * HR_best['EnvironmentSatisfaction'] * HR_best['WorkLifeBalance']) / (HR_best['OverTime_Yes']+1) -> -0.20 correlation\n",
    "\n",
    "# 1. Tenure-to-Experience Ratio (loyalty indicator)\n",
    "HR_best['TenureExperienceRatio'] = HR_best['YearsAtCompanyLog'] / (HR_best['TotalWorkingYearsLog'] + 1e-5)\n",
    "        \n",
    "# 2. Income per Year of Experience (earning efficiency)\n",
    "HR_best['IncomePerExperience'] = HR_1_1['MonthlyIncomeLog'] / (HR_best['TotalWorkingYearsLog'] + 1e-5)\n",
    "        \n",
    "# 3. Promotion Recency Score (career momentum)\n",
    "HR_best['PromotionRecency'] = HR_best['YearsAtCompanyLog'] - HR_1_1['YearsSinceLastPromotionLog']\n",
    "\n",
    "HR_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "# Calculate point biserial correlation\n",
    "variables = ['rate_income', 'WorkLifeBalance_OverTime', 'Job_happiness_score', 'TenureExperienceRatio', 'IncomePerExperience', 'PromotionRecency']\n",
    "for variable in variables:\n",
    "    correlation, p_value = pointbiserialr(HR_best[variable], HR_best['Attrition'])\n",
    "\n",
    "    print(f\"Point Biserial Correlation for {variable}: {correlation:.4f}\")\n",
    "    print(f\"P-value for {variable}: {p_value:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df6585",
   "metadata": {},
   "source": [
    "Job happiness score seems very significantly correlated with Attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e26aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_HR_best = HR_best.corr(method='spearman', numeric_only=True)\n",
    "correlation_HR_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ebe0ce",
   "metadata": {},
   "source": [
    "### **3.2. Testing whether new variables introduce redundant information**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c0b79",
   "metadata": {},
   "source": [
    "We should now test whether the new feature engineering variables generate new redundant information with the previous dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was meant to test whether the new feature engineering variables are redundant with the rest\n",
    "\n",
    "# If two variables are correlated, we drop one of them, keeping the variable with largest correlation with the target\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = HR_best.corr().abs()\n",
    "\n",
    "# Target variable correlation\n",
    "target = 'Attrition'\n",
    "target_corr = corr_matrix[target].drop(target)  # drop self-correlation\n",
    "\n",
    "# Correlation threshold\n",
    "threshold = 0.65\n",
    "\n",
    "# Initialize set for dropped columns\n",
    "drop_cols = set()\n",
    "\n",
    "# Iterate over the upper triangle of the correlation matrix\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    col1 = corr_matrix.columns[i]\n",
    "    if col1 == target or col1 in drop_cols:\n",
    "        continue\n",
    "\n",
    "    for j in range(i + 1, len(corr_matrix.columns)):\n",
    "        col2 = corr_matrix.columns[j]\n",
    "        if col2 == target or col2 in drop_cols:\n",
    "            continue\n",
    "\n",
    "        # Check correlation between two features\n",
    "        if corr_matrix.iloc[i, j] > threshold:\n",
    "            # Compare correlation with target\n",
    "            corr1 = target_corr.get(col1, 0)\n",
    "            corr2 = target_corr.get(col2, 0)\n",
    "\n",
    "            # Drop the one with smaller correlation to target\n",
    "            if corr1 >= corr2:\n",
    "                drop_cols.add(col2)\n",
    "            else:\n",
    "                drop_cols.add(col1)\n",
    "\n",
    "print(\"Columns to drop due to high correlation:\", drop_cols)\n",
    "print(\"Number of columns to drop:\", len(drop_cols))\n",
    "\n",
    "# Create final dataset\n",
    "#HR_best_final = HR_best.drop(columns=list(drop_cols))\n",
    "#print(\"Final dataset shape:\", HR_best_final.shape)\n",
    "#HR_best_final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d9fcc6",
   "metadata": {},
   "source": [
    "The previous cell suggested we remove WorkLifeBalance, as it was significantly correlated (>0.65) with WorkLifeBalance_OverTime.\n",
    "\n",
    "However, we will make the decision of keeping WorkLifeBalance instead of the new feature engineered variable.\n",
    "\n",
    "We will keep Job_happiness_score as it was not considered redundant with its original variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc48071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop WorkLifeBalance_OverTime\n",
    "HR_best.drop('WorkLifeBalance_OverTime', axis=1, inplace=True)\n",
    "HR_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555fb6b",
   "metadata": {},
   "source": [
    "### **3.3. Final correlation plot of the best and engineered variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_final = HR_best.corr()\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(corr_final, cmap=\"PRGn\", square=True, linewidths=0.5, vmin=-0.6, vmax=0.6, annot=False, cbar_kws={\n",
    "        'shrink': 0.6,      # Makes colorbar smaller (60% of default)\n",
    "        'aspect': 30,        # Makes colorbar narrower\n",
    "        'pad': 0.02          # Adds space between plot and colorbar\n",
    "    })\n",
    "plt.title(\"Numerical Correlations (Spearman)\")\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a726708e",
   "metadata": {},
   "source": [
    "The plot above shows that all the features that remain in the dataset are somehow correlated with Attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4804ca",
   "metadata": {},
   "source": [
    "## **4. Saving the best DataFrame and Final Insights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "HR_best.to_csv('data/processed/HR_best_features.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad7dbf",
   "metadata": {},
   "source": [
    "The variables: \n",
    "- BusinessTravel\n",
    "- Department\n",
    "- EnvironmentSatisfaction\n",
    "- JobInvolvement\n",
    "- JobRole\n",
    "- JobSatisfaction \n",
    "- MaritalStatus\n",
    "- NumCompaniesWorked\n",
    "- OverTime  \n",
    "- TotalWorkingYears\n",
    "- WorkLifeBalance\n",
    "- YearsAtCompany\n",
    "\n",
    "all seem relevant to predict if a person will leave the company or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
